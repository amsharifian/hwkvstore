\begin{block}{Motivation}
    \footnotesize
    \begin{itemize}
        \item In datacenter applications, path through CPU/kernel/application accounts for 86\% of total request latency
        \item \alert{Goal}: Serve popular requests without CPU interruption
        \item \alert{Solution}: Hardware key-value store attached to the network interface controller
        \item Many workloads have an access pattern suitable for a small
        dedicated cache
            \begin{itemize}
                \footnotesize
                \item Per a Facebook study, 10\% of keys represents 90\% of requests
                \item Most values are relatively small in size (\SI{1}{\kilo\byte})
            \end{itemize}

    \end{itemize}
%In Memcached in cluster mode, the software stack of the end host takes about
%86-95 percent of the total latency. A large part of that latency comes from the
%fact that we have to interrupt the CPU on every packet that it processes. Our
%insight is that by servicing hot requests on an FPGA instead of in software, we
%can substantially reduce the latency for most requests.

\end{block}

\vspace{1ex}

\begin{block}{Related Work}
\footnotesize
\begin{itemize}
    \item A 2013 paper by Lim et al. proposed a system dubbed
        ``Thin Servers with Smart Pipes'', which served memcached GET requests
        from FPGA hardware.
    \item However, the FPGA hardware handled GET requests by accessing DRAM,
        not a local SRAM cache.
\end{itemize}

\end{block}
